{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, name, accepting=False):\n",
    "        self.name = name\n",
    "        self.transitions = {}\n",
    "        self.accepting = False\n",
    "\n",
    "    def add_transition(self, symbol, target_state):\n",
    "        # Add a transition from this state to the target state\n",
    "        # on the given symbol. If a transition on the given\n",
    "        # symbol already exists, it is replaced.\n",
    "        self.transitions[symbol] = target_state\n",
    "        return target_state        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class NFA:\n",
    "    def __init__(self,states, starting_state=None, accepting_states=[]):\n",
    "        self.states = states\n",
    "        self.starting_state = starting_state\n",
    "        self.accepting_states= accepting_states    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "      \"startingState\": \"S0\",\n",
      "      \"S0\": {\n",
      "            \"a\": [\n",
      "                  \"S1\"\n",
      "            ]\n",
      "      },\n",
      "      \"S1\": {\n",
      "            \"ε\": [\n",
      "                  \"S4\"\n",
      "            ]\n",
      "      },\n",
      "      \"S2\": {\n",
      "            \"b\": [\n",
      "                  \"S3\"\n",
      "            ]\n",
      "      },\n",
      "      \"S3\": {\n",
      "            \"ε\": [\n",
      "                  \"S5\",\n",
      "                  \"S2\"\n",
      "            ]\n",
      "      },\n",
      "      \"S4\": {\n",
      "            \"ε\": [\n",
      "                  \"S2\"\n",
      "            ]\n",
      "      },\n",
      "      \"S5\": {\n",
      "            \"isTerminatingState\": true\n",
      "      }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "class NFA:\n",
    "    def __init__(self, states, starting_state=None, accepting_states=[]):\n",
    "        self.states = states\n",
    "        self.starting_state = starting_state\n",
    "        self.accepting_states = accepting_states\n",
    "\n",
    "class State:\n",
    "    def __init__(self, name, accepting=False):\n",
    "        self.name = name\n",
    "        self.transitions = {}  # Dictionary: {symbol: [target_states]}\n",
    "        self.accepting = accepting\n",
    "\n",
    "    def add_transition(self, symbol, target_state):\n",
    "        if symbol not in self.transitions:\n",
    "            self.transitions[symbol] = []\n",
    "        self.transitions[symbol].append(target_state)\n",
    "\n",
    "def new_state(state_counter, accepting=False):\n",
    "    state = State(f\"S{state_counter}\", accepting)\n",
    "    return state\n",
    "\n",
    "def handle_character(stack, state_counter, symbol):\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "    start.add_transition(symbol, end)\n",
    "    stack.append(NFA([start, end], start, [end]))\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_concatenation(stack, state_counter):\n",
    "    if len(stack) < 2:\n",
    "        raise ValueError(\"Invalid postfix expression for concatenation\")\n",
    "    nfa2 = stack.pop()\n",
    "    nfa1 = stack.pop()\n",
    "    for accepting_state in nfa1.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', nfa2.starting_state)\n",
    "    combined_nfa = NFA(nfa1.states + nfa2.states, nfa1.starting_state, nfa2.accepting_states)\n",
    "    stack.append(combined_nfa)\n",
    "    return combined_nfa,state_counter\n",
    "\n",
    "def handle_or(stack, state_counter):\n",
    "    nfa2 = stack.pop()\n",
    "    nfa1 = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa1.starting_state)\n",
    "    start.add_transition('ε', nfa2.starting_state)\n",
    "\n",
    "    for accepting_state in nfa1.accepting_states + nfa2.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "\n",
    "    combined_nfa = NFA(nfa1.states + nfa2.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_kleene_star(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "    start.add_transition('ε', end)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "        accepting_state.add_transition('ε', nfa.starting_state)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_one_or_more(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "        accepting_state.add_transition('ε', nfa.starting_state)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_zero_or_one(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "    start.add_transition('ε', end)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def construct_nfa(postfix_regex):\n",
    "    state_counter = 0\n",
    "    stack = []\n",
    "\n",
    "    for symbol in postfix_regex:\n",
    "        if symbol.isalnum():\n",
    "            state_counter = handle_character(stack, state_counter, symbol)\n",
    "        elif symbol == '.':\n",
    "            state_counter=handle_concatenation(stack, state_counter)\n",
    "        elif symbol == '|':\n",
    "            state_counter = handle_or(stack, state_counter)\n",
    "        elif symbol == '*':\n",
    "            state_counter = handle_kleene_star(stack, state_counter)\n",
    "        elif symbol == '+':\n",
    "            state_counter = handle_one_or_more(stack, state_counter)\n",
    "        elif symbol == '?':\n",
    "            state_counter = handle_zero_or_one(stack, state_counter)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid symbol in postfix regex: {symbol}\")\n",
    "\n",
    "    return stack.pop()\n",
    "\n",
    "def nfa_to_json(nfa):\n",
    "    nfa_dict = {\n",
    "        \"startingState\": nfa.starting_state.name,\n",
    "    }\n",
    "\n",
    "    for state in nfa.states:\n",
    "        transitions = {symbol: [target.name for target in targets] for symbol, targets in state.transitions.items()}\n",
    "        if state.accepting:\n",
    "            transitions[\"isTerminatingState\"] = True\n",
    "        nfa_dict[state.name] = transitions\n",
    "\n",
    "    return json.dumps(nfa_dict, indent=6, ensure_ascii=False)\n",
    "\n",
    "# Example usage\n",
    "postfix_regex = \"ab|c|d|e|f|g|?o+.\"\n",
    "postfix_regex=\"ab+.\"\n",
    "nfa = construct_nfa(postfix_regex)\n",
    "print(nfa_to_json(nfa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed parts: ['a', 'b']\n",
      "{\n",
      "    \"startingState\": \"S0\",\n",
      "    \"S0\": {\n",
      "        \"isTerminatingState\": false,\n",
      "        \"epsilon\": [\n",
      "            \"S2\",\n",
      "            \"S4\"\n",
      "        ]\n",
      "    },\n",
      "    \"S1\": {\n",
      "        \"isTerminatingState\": true\n",
      "    },\n",
      "    \"S2\": {\n",
      "        \"isTerminatingState\": false,\n",
      "        \"a\": [\n",
      "            \"S3\"\n",
      "        ]\n",
      "    },\n",
      "    \"S3\": {\n",
      "        \"isTerminatingState\": false,\n",
      "        \"epsilon\": [\n",
      "            \"S1\"\n",
      "        ]\n",
      "    },\n",
      "    \"S4\": {\n",
      "        \"isTerminatingState\": false,\n",
      "        \"b\": [\n",
      "            \"S5\"\n",
      "        ]\n",
      "    },\n",
      "    \"S5\": {\n",
      "        \"isTerminatingState\": false,\n",
      "        \"epsilon\": [\n",
      "            \"S1\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "regex = \"a|b\"\n",
    "nfa = NFA()\n",
    "print(nfa.construct_or(regex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed parts: ['a', 'b']\n",
      "['a', 'b']\n",
      "Parsed parts: ['abc', 'de']\n",
      "['abc', 'de']\n",
      "Parsed parts: ['a', '(bc)', 'd']\n",
      "['a', '(bc)', 'd']\n",
      "Parsed parts: ['a', 'b', 'c']\n",
      "['a', 'b', 'c']\n",
      "Parsed parts: ['a(b|c)d']\n",
      "['a(b|c)d']\n",
      "Parsed parts: ['ab']\n",
      "['ab']\n"
     ]
    }
   ],
   "source": [
    "def parse_or(expression):\n",
    "    parts = []\n",
    "    current = []\n",
    "    depth = 0 \n",
    "    \n",
    "    for i, char in enumerate(expression):\n",
    "        if char == '(':\n",
    "            depth += 1\n",
    "        elif char == ')':\n",
    "            depth -= 1\n",
    "        elif char == '|' and depth == 0:\n",
    "            # Split only if outside parentheses\n",
    "            parts.append(''.join(current))\n",
    "            current = []\n",
    "            continue\n",
    "        \n",
    "        current.append(char)\n",
    "\n",
    "    parts.append(''.join(current))\n",
    "    \n",
    "    print(\"Parsed parts:\", parts)\n",
    "    return parts\n",
    "\n",
    "# ✅ Test cases\n",
    "print(parse_or(\"a|b\"))           # ['a', 'b']\n",
    "print(parse_or(\"abc|de\"))        # ['abc', 'de']\n",
    "print(parse_or(\"a|(bc)|d\"))      # ['a', '(bc)', 'd']\n",
    "print(parse_or(\"a|b|c\"))         # ['a', 'b', 'c']\n",
    "print(parse_or(\"a(b|c)d\"))       # ['a(b|c)d']\n",
    "print(parse_or(\"ab\"))     # ['a', '(b|c)', 'd']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shunting Yard Algorithm\n",
    "\n",
    "convert infix to postfix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regex after replacing dot  : \n",
      "[a-g]?o+\n",
      "\n",
      "Regex after replacing square brackets  : \n",
      "(a|b|c|d|e|f|g)?o+\n",
      "\n",
      "Regex after adding concatination  : \n",
      "(a|b|c|d|e|f|g)?o+\n",
      "\n",
      "POSTFIX :\n",
      "ab|c|d|e|f|g|?o+.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_square(regex):\n",
    "    i = 0\n",
    "    regex = list(regex)\n",
    "    while(i < len(regex)):\n",
    "        if regex[i] == '[':\n",
    "            regex[i] = '('\n",
    "            while(regex[i] != ']'):\n",
    "                if regex[i] == '-':\n",
    "                    first = regex[i-1]\n",
    "                    last = regex[i+1]\n",
    "                    chars_between = [chr(i) for i in range(ord(first) + 1, ord(last)+1)]\n",
    "                    str = []\n",
    "                    for c in chars_between:\n",
    "                        str.append(\"|\")\n",
    "                        str.append(c)\n",
    "                    str.append('|')\n",
    "                    regex[i:i+2] = str\n",
    "                else : \n",
    "                    # print(regex[i],regex[i+1])\n",
    "                    if regex[i] != '(' and regex[i] != '|' and regex[i+1] != '|' and regex[i+1] != '-': \n",
    "                        regex.insert(i+1, '|')\n",
    "                i += 1\n",
    "            regex[i-1:i+1] = ')'\n",
    "        else :\n",
    "            i = i + 1\n",
    "    return ''.join(regex)\n",
    "\n",
    "\n",
    "def replace_dot(regex):\n",
    "    result = []\n",
    "    regex = ''.join(regex)\n",
    "    \n",
    "    for curr in regex:\n",
    "        if curr == '.':\n",
    "            result.append(\"[a-zA-Z0-9]\")\n",
    "        else : \n",
    "            result.append(curr)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def add_concat(regex):\n",
    "    result = []\n",
    "    prev = None\n",
    "\n",
    "    for curr in regex:\n",
    "        if prev and (prev.isalnum() or prev in ('*', '+', ')','?')) and (curr.isalnum() or curr == '(' ):\n",
    "            result.append('·')  \n",
    "        result.append(curr)\n",
    "        prev = curr\n",
    "    return ''.join(result)\n",
    "\n",
    "def preprocessing(regex):\n",
    "\n",
    "    regex = replace_dot(regex)\n",
    "    print(\"\\nRegex after replacing dot  : \")\n",
    "    print(regex)\n",
    "    regex = replace_square(regex)\n",
    "    print(\"\\nRegex after replacing square brackets  : \")\n",
    "    print(regex)\n",
    "    # regex = add_concat(regex)\n",
    "    print(\"\\nRegex after adding concatination  : \")\n",
    "    print(regex)    \n",
    "    return regex\n",
    "\n",
    "\n",
    "\n",
    "def infix_to_postfix(infix):\n",
    "    try:\n",
    "        re.compile(infix)\n",
    "    except re.error:\n",
    "        print(\"Invalid regex\")\n",
    "        return None\n",
    "    # Add implicit concatenation operator ('.')\n",
    "    output = []\n",
    "    for i, char in enumerate(infix):\n",
    "        output.append(char)\n",
    "        \n",
    "        if i < len(infix) - 1:\n",
    "            next_char = infix[i + 1]\n",
    "            if char not in \"(|.\" and next_char not in \")*+?|)\":\n",
    "                output.append('.')\n",
    "    infix = output\n",
    "\n",
    "    precedence = { '*' : 5, '+' : 4, '?' : 3 , '.' : 2 , '|' : 1 , '(' : 0 }\n",
    "\n",
    "    infix = list(infix)\n",
    "    stack = []\n",
    "    postfix = []\n",
    "    for i,char in enumerate(infix):\n",
    "        \n",
    "        if char == '(':\n",
    "            stack.append(char)\n",
    "        \n",
    "        elif char == \")\":\n",
    "            stack_top = stack.pop()\n",
    "            while stack_top != \"(\":\n",
    "                postfix.append(stack_top)\n",
    "                stack_top = stack.pop()\n",
    "        \n",
    "        elif char in ['*','+','?','.','|']:\n",
    "            stack_top = None\n",
    "            if len(stack) > 0:\n",
    "                stack_top = stack.pop()\n",
    "            while stack_top != None  and precedence[char] <= precedence[stack_top]:\n",
    "                postfix.append(stack_top)\n",
    "                if len(stack) != 0:\n",
    "                    stack_top = stack.pop()\n",
    "                else :\n",
    "                    break\n",
    "            if stack_top != None and precedence[char] > precedence[stack_top]:\n",
    "                stack.append(stack_top)\n",
    "            stack.append(char)\n",
    "        \n",
    "        else:\n",
    "            postfix.append(char)\n",
    "                        \n",
    "    \n",
    "    while stack:\n",
    "        top = stack.pop()\n",
    "        if top == '(':\n",
    "            print(\"Unbalanced parentheses\")\n",
    "            return None\n",
    "        postfix.append(top)\n",
    "    \n",
    "    return ''.join(postfix)\n",
    "\n",
    "\n",
    "infix = \"[a-g]?o+\"\n",
    "# infix=\"a+b\"\n",
    "preprocessed_infix = preprocessing(infix)\n",
    "print(\"\\nPOSTFIX :\")\n",
    "print(infix_to_postfix(preprocessed_infix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a+b.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
