{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shunting Yard Algorithm\n",
    "\n",
    "convert infix to postfix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regex after replacing dot  : \n",
      "(a*)*\n",
      "\n",
      "Regex after replacing square brackets  : \n",
      "(a*)*\n",
      "\n",
      "Regex after adding concatination  : \n",
      "(a*)*\n",
      "\n",
      "POSTFIX :\n",
      "a**\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def solve_or_in_brackets(regex):\n",
    "    # loop over the string to add | between any two consecutive characters inside square brackets\n",
    "    i = 0\n",
    "    regex = list(regex)\n",
    "    while(i < len(regex)):\n",
    "        if regex[i] == '[':\n",
    "            while(regex[i] != ']'):\n",
    "                if regex[i].isalnum() and regex[i+1].isalnum():\n",
    "                    regex.insert(i+1, '|')\n",
    "                i += 1\n",
    "        else :\n",
    "            i = i + 1\n",
    "    return ''.join(regex)\n",
    "\n",
    "\n",
    "def solve_ranges_in_brackets(regex):\n",
    "    # loop over the string to add ranges of characters inside square brackets\n",
    "    i = 0\n",
    "    regex = list(regex)\n",
    "    while(i < len(regex)):\n",
    "        if regex[i] == '[':\n",
    "            regex[i] = '('\n",
    "            while(regex[i] != ']'):\n",
    "                if regex[i] == '-':\n",
    "                    first = regex[i-1]\n",
    "                    last = regex[i+1]\n",
    "                    chars_between = [chr(i) for i in range(ord(first) + 1, ord(last))]\n",
    "                    str = []\n",
    "                    for c in chars_between:\n",
    "                        str.append(\"|\")\n",
    "                        str.append(c)\n",
    "                    str.append('|')\n",
    "                    regex[i:i+1] = str\n",
    "                    print(''.join(regex))\n",
    "                i += 1\n",
    "            regex[i] = ')'\n",
    "        else :\n",
    "            i = i + 1\n",
    "    return ''.join(regex)\n",
    "\n",
    "def replace_square(regex):\n",
    "    regex = solve_or_in_brackets(regex)\n",
    "    regex = solve_ranges_in_brackets(regex)\n",
    "    return regex\n",
    "\n",
    "# def replace_square(regex):\n",
    "#     i = 0\n",
    "#     regex = list(regex)\n",
    "#     while(i < len(regex)):\n",
    "#         if regex[i] == '[':\n",
    "#             regex[i] = '('\n",
    "#             while(regex[i] != ']'):\n",
    "#                 if regex[i] == '-':\n",
    "#                     first = regex[i-1]\n",
    "#                     last = regex[i+1]\n",
    "#                     chars_between = [chr(i) for i in range(ord(first) + 1, ord(last)+1)]\n",
    "#                     str = []\n",
    "#                     for c in chars_between:\n",
    "#                         str.append(\"|\")\n",
    "#                         str.append(c)\n",
    "#                     str.append('|')\n",
    "#                     regex[i:i+2] = str\n",
    "#                 else : \n",
    "#                     # print(regex[i],regex[i+1])\n",
    "#                     if regex[i] != '(' and regex[i] != '|' and regex[i+1] != '|' and regex[i+1] != '-': \n",
    "#                         regex.insert(i+1, '|')\n",
    "#                 i += 1\n",
    "#             regex[i-1:i+1] = ')'\n",
    "#         else :\n",
    "#             i = i + 1\n",
    "#     return ''.join(regex)\n",
    "\n",
    "def replace_dot(regex):\n",
    "    result = []\n",
    "    regex = ''.join(regex)\n",
    "    \n",
    "    for curr in regex:\n",
    "        if curr == '.':\n",
    "            result.append(\"[a-zA-Z0-9]\")\n",
    "        else : \n",
    "            result.append(curr)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def add_concat(regex):\n",
    "    result = []\n",
    "    prev = None\n",
    "\n",
    "    for curr in regex:\n",
    "        if prev and (prev.isalnum() or prev in ('*', '+', ')','?')) and (curr.isalnum() or curr == '(' ):\n",
    "            result.append('·')  \n",
    "        result.append(curr)\n",
    "        prev = curr\n",
    "    return ''.join(result)\n",
    "\n",
    "def preprocessing(regex):\n",
    "\n",
    "    regex = replace_dot(regex)\n",
    "    print(\"\\nRegex after replacing dot  : \")\n",
    "    print(regex)\n",
    "    regex = replace_square(regex)\n",
    "    print(\"\\nRegex after replacing square brackets  : \")\n",
    "    print(regex)\n",
    "    # regex = add_concat(regex)\n",
    "    print(\"\\nRegex after adding concatination  : \")\n",
    "    print(regex)    \n",
    "    return regex\n",
    "\n",
    "\n",
    "\n",
    "def infix_to_postfix(infix):\n",
    "    try:\n",
    "        re.compile(infix)\n",
    "    except re.error:\n",
    "        print(\"Invalid regex\")\n",
    "        return None\n",
    "    # Add implicit concatenation operator ('.')\n",
    "    output = []\n",
    "    for i, char in enumerate(infix):\n",
    "        output.append(char)\n",
    "        \n",
    "        if i < len(infix) - 1:\n",
    "            next_char = infix[i + 1]\n",
    "            if char not in \"(|.\" and next_char not in \")*+?|)\":\n",
    "                output.append('.')\n",
    "    infix = output\n",
    "\n",
    "    precedence = { '*' : 5, '+' : 4, '?' : 3 , '.' : 2 , '|' : 1 , '(' : 0 }\n",
    "\n",
    "    infix = list(infix)\n",
    "    stack = []\n",
    "    postfix = []\n",
    "    for i,char in enumerate(infix):\n",
    "        \n",
    "        if char == '(':\n",
    "            stack.append(char)\n",
    "        \n",
    "        elif char == \")\":\n",
    "            stack_top = stack.pop()\n",
    "            while stack_top != \"(\":\n",
    "                postfix.append(stack_top)\n",
    "                stack_top = stack.pop()\n",
    "        \n",
    "        elif char in ['*','+','?','.','|']:\n",
    "            stack_top = None\n",
    "            if len(stack) > 0:\n",
    "                stack_top = stack.pop()\n",
    "            while stack_top != None  and precedence[char] <= precedence[stack_top]:\n",
    "                postfix.append(stack_top)\n",
    "                if len(stack) != 0:\n",
    "                    stack_top = stack.pop()\n",
    "                else :\n",
    "                    break\n",
    "            if stack_top != None and precedence[char] > precedence[stack_top]:\n",
    "                stack.append(stack_top)\n",
    "            stack.append(char)\n",
    "        \n",
    "        else:\n",
    "            postfix.append(char)\n",
    "                        \n",
    "    \n",
    "    while stack:\n",
    "        top = stack.pop()\n",
    "        if top == '(':\n",
    "            print(\"Unbalanced parentheses\")\n",
    "            return None\n",
    "        postfix.append(top)\n",
    "    \n",
    "    return ''.join(postfix)\n",
    "\n",
    "\n",
    "infix = \"[a-g]?o+\"\n",
    "infix=\"(a*)*\"\n",
    "preprocessed_infix = preprocessing(infix)\n",
    "print(\"\\nPOSTFIX :\")\n",
    "print(infix_to_postfix(preprocessed_infix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postfix to nfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class NFA:\n",
    "    def __init__(self, states, starting_state=None, accepting_states=[]):\n",
    "        self.states = states\n",
    "        self.starting_state = starting_state\n",
    "        self.accepting_states = accepting_states\n",
    "\n",
    "class State1:\n",
    "    def __init__(self, name, accepting=False):\n",
    "        self.name = name\n",
    "        self.transitions = {}  # Dictionary: {symbol: [target_states]}\n",
    "        self.accepting = accepting\n",
    "\n",
    "    def add_transition(self, symbol, target_state):\n",
    "        if symbol not in self.transitions:\n",
    "            self.transitions[symbol] = []\n",
    "        self.transitions[symbol].append(target_state)\n",
    "\n",
    "def new_state(state_counter, accepting=False):\n",
    "    state = State1(f\"S{state_counter}\", accepting)\n",
    "    return state\n",
    "\n",
    "def handle_character(stack, state_counter, symbol):\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "    start.add_transition(symbol, end)\n",
    "    stack.append(NFA([start, end], start, [end]))\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_concatenation(stack, state_counter):\n",
    "    if len(stack) < 2:\n",
    "        raise ValueError(\"Invalid postfix expression for concatenation\")\n",
    "    nfa2 = stack.pop()\n",
    "    nfa1 = stack.pop()\n",
    "    for accepting_state in nfa1.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', nfa2.starting_state)\n",
    "    combined_nfa = NFA(nfa1.states + nfa2.states, nfa1.starting_state, nfa2.accepting_states)\n",
    "    stack.append(combined_nfa)\n",
    "    return combined_nfa,state_counter\n",
    "\n",
    "def handle_or(stack, state_counter):\n",
    "    nfa2 = stack.pop()\n",
    "    nfa1 = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa1.starting_state)\n",
    "    start.add_transition('ε', nfa2.starting_state)\n",
    "\n",
    "    for accepting_state in nfa1.accepting_states + nfa2.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "\n",
    "    combined_nfa = NFA(nfa1.states + nfa2.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_kleene_star(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "    start.add_transition('ε', end)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "        accepting_state.add_transition('ε', start)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_one_or_more(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "        accepting_state.add_transition('ε', nfa.starting_state)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def handle_zero_or_one(stack, state_counter):\n",
    "    nfa = stack.pop()\n",
    "    start = new_state(state_counter)\n",
    "    end = new_state(state_counter + 1, True)\n",
    "\n",
    "    start.add_transition('ε', nfa.starting_state)\n",
    "    start.add_transition('ε', end)\n",
    "\n",
    "    for accepting_state in nfa.accepting_states:\n",
    "        accepting_state.accepting = False\n",
    "        accepting_state.add_transition('ε', end)\n",
    "\n",
    "    combined_nfa = NFA(nfa.states + [start, end], start, [end])\n",
    "    stack.append(combined_nfa)\n",
    "    return state_counter + 2\n",
    "\n",
    "def construct_nfa(postfix_regex):\n",
    "    state_counter = 1\n",
    "    stack = []\n",
    "\n",
    "    for symbol in postfix_regex:\n",
    "        if symbol.isalnum():\n",
    "            state_counter = handle_character(stack, state_counter, symbol)\n",
    "        elif symbol == '.':\n",
    "            _,state_counter=handle_concatenation(stack, state_counter)\n",
    "        elif symbol == '|':\n",
    "            state_counter = handle_or(stack, state_counter)\n",
    "        elif symbol == '*':\n",
    "            state_counter = handle_kleene_star(stack, state_counter)\n",
    "        elif symbol == '+':\n",
    "            state_counter = handle_one_or_more(stack, state_counter)\n",
    "        elif symbol == '?':\n",
    "            state_counter = handle_zero_or_one(stack, state_counter)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid symbol in postfix regex: {symbol}\")\n",
    "\n",
    "    return stack.pop()\n",
    "\n",
    "def nfa_to_json(nfa):\n",
    "    nfa_dict = {\n",
    "        \"startingState\": nfa.starting_state.name,\n",
    "    }\n",
    "\n",
    "    for state in nfa.states:\n",
    "        transitions = {symbol: [target.name for target in targets] for symbol, targets in state.transitions.items()}\n",
    "        if state.accepting:\n",
    "            transitions[\"isTerminatingState\"] = True\n",
    "        nfa_dict[state.name] = transitions\n",
    "\n",
    "    return json.dumps(nfa_dict, indent=6, ensure_ascii=False)\n",
    "def save_nfa_to_file(nfa, filename):\n",
    "    nfa_json = nfa_to_json(nfa)\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(nfa_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_nfa(nfa):\n",
    "    dot = Digraph(format='png')\n",
    "    dot.attr(rankdir='LR')\n",
    "\n",
    "    # Define the starting state\n",
    "    dot.node(nfa.starting_state.name, shape='circle', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    # Define the states\n",
    "    for state in nfa.states:\n",
    "        shape = 'doublecircle' if state.accepting else 'circle'\n",
    "        dot.node(state.name, shape=shape)\n",
    "\n",
    "    # Add transitions\n",
    "    for state in nfa.states:\n",
    "        for symbol, targets in state.transitions.items():\n",
    "            for target in targets:\n",
    "                dot.edge(state.name, target.name, label=symbol)\n",
    "\n",
    "    # Add an initial arrow\n",
    "    dot.node('start', shape='none', label='')\n",
    "    dot.edge('start', nfa.starting_state.name)\n",
    "\n",
    "    # Save and render\n",
    "    dot.render('nfa_visualization', view=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regex after replacing dot  : \n",
      "(a*b)(b?a+)\n",
      "\n",
      "Regex after replacing square brackets  : \n",
      "(a*b)(b?a+)\n",
      "\n",
      "Regex after adding concatination  : \n",
      "(a*b)(b?a+)\n",
      "\n",
      "POSTFIX :\n",
      "a*b.b?a+..\n"
     ]
    }
   ],
   "source": [
    "regex=\"(a*b)(b?a+)\"\n",
    "preprocessed_infix = preprocessing(regex)\n",
    "print(\"\\nPOSTFIX :\")\n",
    "postfix_regex=infix_to_postfix(preprocessed_infix)\n",
    "print(postfix_regex)\n",
    "\n",
    "nfa = construct_nfa(postfix_regex)\n",
    "\n",
    "visualize_nfa(nfa)\n",
    "\n",
    "save_nfa_to_file(nfa, \"nfa_output.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startingState': 'S3',\n",
       " 'S1': {'a': ['S2']},\n",
       " 'S2': {'ε': ['S4', 'S1']},\n",
       " 'S3': {'ε': ['S1']},\n",
       " 'S4': {'ε': ['S5']},\n",
       " 'S5': {'b': ['S6']},\n",
       " 'S6': {'isTerminatingState': True}}"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from output json to input of part2\n",
    "import json\n",
    "def normalize_nfa(NFA):\n",
    "    normalized_nfa = {}\n",
    "\n",
    "    for state, transitions in NFA.items():\n",
    "        # Preserve the starting state without modification\n",
    "        if state == \"startingState\":\n",
    "            normalized_nfa[state] = transitions\n",
    "            continue\n",
    "\n",
    "        normalized_nfa[state] = {}\n",
    "        \n",
    "        for symbol, target in transitions.items():\n",
    "            if symbol == \"isTerminatingState\":\n",
    "                normalized_nfa[state][symbol] = target\n",
    "            else:\n",
    "                # Ensure all targets are lists (even empty ones)\n",
    "                if not isinstance(target, list):\n",
    "                    target = [target] if target else []\n",
    "                normalized_nfa[state][symbol] = target\n",
    "\n",
    "        # Ensure states with no actions are represented as an empty list\n",
    "        if not transitions:\n",
    "            normalized_nfa[state] = {}\n",
    "\n",
    "    return normalized_nfa\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r',encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Failed to decode JSON from the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "#read json file in dict\n",
    "nfa_dict=read_json_file(\"nfa_output.json\")\n",
    "normalize_nfa(nfa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import graphviz\n",
    "class State:\n",
    "    def __init__(self, name, elements):\n",
    "        self.name = name\n",
    "        self.elements = frozenset(elements)  # Ensure it's hashable\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.elements)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.elements == other.elements\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"State({self.name}, {sorted(self.elements)})\"\n",
    "\n",
    "class DFA:\n",
    "    def __init__(self):\n",
    "        self.states = {}  # Now stores State objects as values\n",
    "        self.startingState = None\n",
    "        self.transitions = {}\n",
    "        self.acceptingStates = set()\n",
    "\n",
    "    def add_state(self, state, is_accepting=False):\n",
    "        self.states[state.name] = state\n",
    "        if is_accepting:\n",
    "            self.acceptingStates.add(state)\n",
    "\n",
    "    def add_transition(self, from_state, to_state, symbol):\n",
    "        if from_state.name not in self.transitions.keys():\n",
    "            self.transitions[from_state.name]={}\n",
    "        if symbol not in self.transitions[from_state.name].keys():\n",
    "            self.transitions[from_state.name][symbol] = set()\n",
    "        self.transitions[from_state.name][symbol].add(to_state.name)\n",
    "        \n",
    "        \n",
    "    def get_transition(self, from_state):\n",
    "        if from_state in self.transitions.keys():\n",
    "            return self.transitions[from_state]\n",
    "        return None\n",
    "\n",
    "    def to_json(self, filename):\n",
    "        dfa_json = {\n",
    "            \"startingState\": self.startingState,\n",
    "            \"acceptingStates\": [state.name for state in self.acceptingStates],\n",
    "            \"transitions\": self.transitions\n",
    "        }\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(dfa_json, f, indent=4)\n",
    "        print(f\"DFA saved to {filename}\")\n",
    "        \n",
    "    def to_json_min(self, filename):\n",
    "        dfa_json = {\n",
    "            \"startingState\": self.startingState.name if self.startingState else None,\n",
    "            \"acceptingStates\": [state.name for state in self.acceptingStates],\n",
    "            \"transitions\": {\n",
    "                from_state: {\n",
    "                    symbol: [to_state for to_state in to_states]\n",
    "                    for symbol, to_states in transitions.items()\n",
    "                }\n",
    "                for from_state, transitions in self.transitions.items()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(dfa_json, f, indent=4)\n",
    "        \n",
    "        print(f\"DFA saved to {filename}\")\n",
    "\n",
    "    def visualize(self, output_file=\"dfa_visualization\"):\n",
    "        dot = graphviz.Digraph(format='png')\n",
    "        dot.attr(rankdir='LR')\n",
    "\n",
    "        # Draw states\n",
    "        for state in self.states.values():\n",
    "            shape = \"doublecircle\" if state in self.acceptingStates else \"circle\"\n",
    "            dot.node(state.name, label=state.name, shape=shape)\n",
    "\n",
    "        # Draw starting arrow\n",
    "        if self.startingState:\n",
    "            dot.node(\"start\", shape=\"point\")\n",
    "            dot.edge(\"start\", self.startingState)\n",
    "\n",
    "        # Draw transitions\n",
    "        for from_state, transitions in self.transitions.items():\n",
    "            for symbol, to_state in transitions.items():\n",
    "                for state in to_state:\n",
    "                    dot.edge(from_state, state, label=symbol)\n",
    "\n",
    "        dot.render(output_file,view=True)\n",
    "        print(f\"DFA visualization saved to {output_file}.png\")\n",
    "    import graphviz\n",
    "\n",
    "    def visualize_min(self, output_file=\"dfa_visualization\"):\n",
    "        dot = graphviz.Digraph(format='png')\n",
    "        dot.attr(rankdir='LR')\n",
    "\n",
    "        # Draw states\n",
    "        for state in self.states.values():\n",
    "            shape = \"doublecircle\" if state in self.acceptingStates else \"circle\"\n",
    "            dot.node(state.name, label=state.name, shape=shape)\n",
    "\n",
    "        # Ensure correct starting state\n",
    "        if self.startingState:\n",
    "            dot.node(\"Start\", shape=\"point\")  \n",
    "            dot.edge(\"Start\", self.startingState.name)  # Explicit label for clarity\n",
    "\n",
    "        # Draw transitions\n",
    "        for from_state, transitions in self.transitions.items():\n",
    "            for symbol, to_state in transitions.items():\n",
    "                for state in to_state:\n",
    "                    dot.edge(from_state, state, label=symbol)\n",
    "\n",
    "        dot.render(output_file, view=True)\n",
    "        print(f\"DFA visualization saved to {output_file}.png\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def is_accepting_state(self, state):\n",
    "        for s in self.acceptingStates:\n",
    "            if s.name == state:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class NFAtoDFAConverter:\n",
    "    def epsilon_closure(self, NFA, state):\n",
    "        closure = {state}\n",
    "        stack = [state]\n",
    "\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if \"ε\" in NFA[current]:\n",
    "                for target in NFA[current][\"ε\"]:\n",
    "                    if target not in closure:\n",
    "                        closure.add(target)\n",
    "                        stack.append(target)\n",
    "\n",
    "        return closure\n",
    "\n",
    "    def convert_to_DFA(self, NFA):\n",
    "        DFA_machine = DFA()\n",
    "\n",
    "        # Step 1: Compute the starting state (ε-closure of NFA start)\n",
    "        start_closure = self.epsilon_closure(NFA, NFA[\"startingState\"])\n",
    "        start_state = State(\"S0\", start_closure)\n",
    "        DFA_machine.add_state(start_state, self.is_accepting_state(NFA, start_closure))\n",
    "        DFA_machine.startingState = start_state.name\n",
    "\n",
    "        # Step 2: Process unmarked states\n",
    "        unmarked_states = [start_state]\n",
    "        processed_states = set()\n",
    "\n",
    "        while unmarked_states:\n",
    "            current_state = unmarked_states.pop()\n",
    "            if current_state in processed_states:\n",
    "                continue\n",
    "            processed_states.add(current_state)\n",
    "\n",
    "            transitions_table = {}\n",
    "\n",
    "            # Step 3: Iterate over all input symbols (exclude ε)\n",
    "            alphabet = self.get_alphabet(NFA)\n",
    "\n",
    "            for nfa_state in current_state.elements:\n",
    "                for action in alphabet:\n",
    "                    if action == 'ε':\n",
    "                        continue\n",
    "                    if action in NFA[nfa_state]:\n",
    "                        next_states = set()\n",
    "                        for next_state in NFA[nfa_state][action]:\n",
    "                            next_states |= self.epsilon_closure(NFA, next_state)\n",
    "                        if action not in transitions_table:\n",
    "                            transitions_table[action] = next_states\n",
    "                        else:\n",
    "                            transitions_table[action] |= next_states\n",
    "\n",
    "            # Step 4: Create new DFA states and transitions\n",
    "            for action, next_states in transitions_table.items():\n",
    "                if not next_states:\n",
    "                    continue\n",
    "\n",
    "                # Ensure consistent naming for new states\n",
    "                \n",
    "                next_state_name = f\"S{len(DFA_machine.states)}\"\n",
    "                # print(\"//////////\",next_states)\n",
    "                # compact_name=\"\"\n",
    "                # for state in next_states:\n",
    "                #     compact_name+=state +','\n",
    "                # compact_name=compact_name[:-1]\n",
    "                    \n",
    "                next_state = State(next_state_name, next_states)\n",
    "\n",
    "                # Check if state already exists\n",
    "                if next_state.elements not in [s.elements for s in DFA_machine.states.values()]:\n",
    "                    unmarked_states.append(next_state)\n",
    "                    DFA_machine.add_state(next_state, self.is_accepting_state(NFA, next_states))\n",
    "                else:\n",
    "                    next_state = next(filter(lambda s: s.elements == next_state.elements, DFA_machine.states.values()))\n",
    "\n",
    "                DFA_machine.add_transition(current_state, next_state, action)\n",
    "\n",
    "        return DFA_machine\n",
    "\n",
    "    def get_alphabet(self, NFA):\n",
    "        alphabet = set()\n",
    "        for transitions in NFA.values():\n",
    "            if not isinstance(transitions, str):\n",
    "                for symbol in transitions.keys():\n",
    "                    if symbol != \"ε\" and symbol != \"isTerminatingState\":\n",
    "                        alphabet.add(symbol)\n",
    "        return alphabet\n",
    "\n",
    "    def is_accepting_state(self, NFA, state_set):\n",
    "        return any(NFA[s].get(\"isTerminatingState\", False) for s in state_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFA visualization saved to dfa.png\n",
      "S0 --b--> {'S1'}\n",
      "S0 --a--> {'S2'}\n",
      "S2 --a--> {'S2'}\n",
      "S2 --b--> {'S1'}\n",
      "S1 --a--> {'S3'}\n",
      "S1 --b--> {'S4'}\n",
      "S4 --a--> {'S3'}\n",
      "S3 --a--> {'S3'}\n"
     ]
    }
   ],
   "source": [
    "converter = NFAtoDFAConverter()\n",
    "dfa = converter.convert_to_DFA(nfa_dict)\n",
    "dfa.visualize(\"dfa\")\n",
    "# dfa.to_json(\"dfa_out.json\")\n",
    "# Output DFA structure\n",
    "# print(\"Starting State:\", dfa.startingState)\n",
    "# print(\"Accepting States:\", dfa.acceptingStates)\n",
    "# print(\"Transitions:\")\n",
    "for from_state, transitions in dfa.transitions.items():\n",
    "    for symbol, to_state in transitions.items():\n",
    "        print(f\"{from_state} --{symbol}--> {to_state}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert DFA to minimized DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convertDFAToMinDFA:\n",
    "    def convert_to_min_dfa(self, dfa: DFA):\n",
    "        # Step 1: Separate accepting and non-accepting states\n",
    "        P, Q = self.separate_acceptence(dfa)\n",
    "        \n",
    "        # Step 2: Create initial partition of states\n",
    "        sets = [P, Q]\n",
    "        new_states = True\n",
    "        \n",
    "        while new_states:\n",
    "            new_states = False\n",
    "            for state_set in sets:\n",
    "                if len(state_set) > 1:\n",
    "                    new_groups = {}\n",
    "                    for state in state_set:\n",
    "                        transition_table = {}\n",
    "                        transitions = dfa.get_transition(state) or {}\n",
    "                        \n",
    "                        for symbol, target_states in transitions.items():\n",
    "                            transition_table[symbol] = frozenset(target_states)\n",
    "                        \n",
    "                        transition_key = frozenset(transition_table.items())\n",
    "                        if transition_key not in new_groups:\n",
    "                            new_groups[transition_key] = {state}\n",
    "                        else:\n",
    "                            new_groups[transition_key].add(state)\n",
    "                    \n",
    "                    if len(new_groups) > 1:\n",
    "                        sets.remove(state_set)\n",
    "                        sets.extend(new_groups.values())\n",
    "                        new_states = True\n",
    "                        break\n",
    "        \n",
    "        sets = [s for s in sets if s]  # Remove empty sets\n",
    "        print(\"Final Sets:\", sets)\n",
    "        \n",
    "        final_dfa = self.create_min_DFA(dfa, sets)\n",
    "        # final_dfa.startingState.name = \"Start\"\n",
    "        return final_dfa\n",
    "    \n",
    "    def separate_acceptence(self, dfa: DFA):\n",
    "        P, Q = set(), set()\n",
    "        for state in dfa.states:\n",
    "            if dfa.is_accepting_state(state):\n",
    "                P.add(state)\n",
    "            else:\n",
    "                Q.add(state)\n",
    "        return P, Q\n",
    "    \n",
    "    def create_min_DFA(self, dfa: DFA, sets) -> DFA:\n",
    "        final_dfa = DFA()\n",
    "        state_mapping = {}\n",
    "        \n",
    "        # Create new states\n",
    "        for idx, states_set in enumerate(sets):\n",
    "            new_state = State(\"S\" + str(idx), frozenset(states_set))\n",
    "            final_dfa.add_state(new_state)\n",
    "            \n",
    "            for state in states_set:\n",
    "                state_mapping[state] = new_state\n",
    "            \n",
    "            if dfa.startingState in states_set:\n",
    "                final_dfa.startingState = new_state\n",
    "            \n",
    "            if any(dfa.is_accepting_state(state) for state in states_set):\n",
    "                final_dfa.acceptingStates.add(new_state)\n",
    "        \n",
    "        print(\"State Mapping:\", state_mapping)\n",
    "        \n",
    "        # Add transitions to the minimized DFA\n",
    "        for from_state, transitions in dfa.transitions.items():\n",
    "            new_from_state = state_mapping[from_state]\n",
    "\n",
    "            for symbol, to_states in transitions.items():\n",
    "                for state in set(to_states):\n",
    "                    new_to_state = state_mapping[state]\n",
    "                    \n",
    "                    existing_transitions = final_dfa.get_transition(new_from_state) or {}\n",
    "                    print(existing_transitions)\n",
    "                    if symbol not in existing_transitions or new_to_state not in existing_transitions[symbol]:\n",
    "                        final_dfa.add_transition(new_from_state, new_to_state, symbol)\n",
    "        \n",
    "        return final_dfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Sets: [{'S3'}, {'S4'}, {'S0', 'S2'}, {'S1'}]\n",
      "State Mapping: {'S3': State(S0, ['S3']), 'S4': State(S1, ['S4']), 'S0': State(S2, ['S0', 'S2']), 'S2': State(S2, ['S0', 'S2']), 'S1': State(S3, ['S1'])}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "DFA visualization saved to dfa_min.png\n",
      "{'S0': State(S0, ['S3']), 'S1': State(S1, ['S4']), 'S2': State(S2, ['S0', 'S2']), 'S3': State(S3, ['S1'])}\n",
      "S2 --b--> {'S3'}\n",
      "S2 --a--> {'S2'}\n",
      "S3 --a--> {'S0'}\n",
      "S3 --b--> {'S1'}\n",
      "S1 --a--> {'S0'}\n",
      "S0 --a--> {'S0'}\n"
     ]
    }
   ],
   "source": [
    "converter = NFAtoDFAConverter()\n",
    "dfa = converter.convert_to_DFA(nfa_dict)\n",
    "# print(dfa.transitions)\n",
    "# dfa.to_json(\"dfa_out.json\")\n",
    "minDFA=convertDFAToMinDFA()\n",
    "final_dfa=minDFA.convert_to_min_dfa(dfa)\n",
    "final_dfa.visualize_min(\"dfa_min\")\n",
    "print(final_dfa.states)\n",
    "# final_dfa.to_json(\"min_json.json\")\n",
    "# Output DFA structure\n",
    "# print(\"Starting State:\", dfa.startingState)\n",
    "# print(\"Accepting States:\", dfa.acceptingStates)\n",
    "# print(\"Transitions:\")\n",
    "for from_state, transitions in final_dfa.transitions.items():\n",
    "    for symbol, to_state in transitions.items():\n",
    "        print(f\"{from_state} --{symbol}--> {to_state}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regex after replacing dot  : \n",
      "a+b\n",
      "\n",
      "Regex after replacing square brackets  : \n",
      "a+b\n",
      "\n",
      "Regex after adding concatination  : \n",
      "a+b\n",
      "\n",
      "POSTFIX :\n",
      "a+b.\n",
      "Final Sets: [{'S2'}, {'S0'}, {'S1'}]\n",
      "State Mapping: {'S2': State(S0, ['S2']), 'S0': State(S1, ['S0']), 'S1': State(S2, ['S1'])}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "DFA visualization saved to dfa_min.png\n",
      "DFA saved to dfa_min.json\n"
     ]
    }
   ],
   "source": [
    "# final cell \n",
    "regex=\"a+b\"\n",
    "preprocessed_infix = preprocessing(regex)\n",
    "print(\"\\nPOSTFIX :\")\n",
    "postfix_regex=infix_to_postfix(preprocessed_infix)\n",
    "print(postfix_regex)\n",
    "\n",
    "nfa = construct_nfa(postfix_regex)\n",
    "\n",
    "visualize_nfa(nfa)\n",
    "\n",
    "save_nfa_to_file(nfa, \"nfa_output.json\")\n",
    "# from NFA to DFA\n",
    "nfa_dict=read_json_file(\"nfa_output.json\")\n",
    "converter = NFAtoDFAConverter()\n",
    "dfa = converter.convert_to_DFA(nfa_dict)\n",
    "# dfa.visualize(\"dfa\")\n",
    "\n",
    "#from DFA to minDFA\n",
    "minDFA=convertDFAToMinDFA()\n",
    "final_dfa=minDFA.convert_to_min_dfa(dfa)\n",
    "final_dfa.visualize_min(\"dfa_min\")\n",
    "final_dfa.to_json_min(\"dfa_min.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
